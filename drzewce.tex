\section{Drzewce}
\sectionauthor{Bartłomiej Betka}

\label{sec:drzewce}

Podobnie jak drzewa AVL oraz drzewa czerwono-czarne drzewce rozwiązują problem potencjalnego niezrównoważenia "zwykłego" BST.
Osiągają one jednak ten cel w zupełnie inny sposób.
Zamiast kontrolować wysokość drzewa i jego poddrzew drzewce opierają się na randomizacji, która, jak zaraz pokażemy, zapewnia asymptotycznie równie dobre oczekiwane własności. 

\begin{definition} 
Drzewiec to drzewo binarne, którego każdy węzeł posiada zarówno klucz jak i priorytet.
Względem kluczy drzewiec jest drzewem przeszukiwań binarnych a względem priorytetów jest on kopcem.
\end{definition}

\paragraph{Podstawowe operacje, które implementują drzewce:}
\begin{itemize}
    \item \textbf{Find} Wygląda dokładnie tak, jak w drzewie BST (względem kluczy).
    \item \textbf{Insert} Najpierw wstawiamy wartość (wraz z losowym kluczem) jak do drzewa BST, następnie rotacjami/zamianą z ojcem przywracamy porządek kopcowy.
    \item \textbf{Delete} Znajdujemy klucz, rotacjami spychamy go do liścia, następnie usuwamy ten liść (co nie zaburza ani porządku BST ani kopca).
    \item Pomocniczo potrzebne są również operacje rotacji służące do przywracania porządku kopcowego.
\end{itemize}

Na końcu rozdziału znajduje się pseudo-kod, który pokazuje jak można zaimplementować powyższe metody i pozwala przekonać się, że jest to znacznie łatwiejsze niż w przypadku analogicznych operacji na drzewach AVL czy drzewach czerwono-czarnych.

Teraz udowodnimy kilka własności drzewców.\footnote{Przy analizie drzewców zakładamy, że wszystkie priorytety są różne.}

\begin{theorem}
\label{unique treap}
 Dla każdego zbioru par $(klucz, priorytet)$ istnieje dokładnie jeden drzewiec.
\end{theorem}
\begin{proof}
Oczywiście para, w której znajduje się najwyższy priorytet musi znajdować się w korzeniu drzewa.
W jego lewym poddrzewie znajdować się muszą wszystkie pary o mniejszych kluczach, a w prawym wszystkie pary o większych kluczach, które, indukcyjnie, tworzą drzewce według tej samej zasady.
\end{proof}

Z twierdzenia tego i jego dowodu wprost wynika, że drzewiec tworzy BST o takim kształcie, jakby kolejne klucze były dodawane w kolejności rosnących priorytetów.

\begin{theorem}
 Oczekiwana wysokość drzewca jest $O(log\ n)$.
\end{theorem}
\begin{proof}

\end{proof}

\begin{theorem}
 Oczekiwana ilość rotacji przy \texttt{insert}/\texttt{delete} < 2.
\end{theorem}
\begin{proof}
Nasz dowód rozpoczniemy od pomocniczej definicji:
\begin{definition}
\textbf{Lewym/Prawym Kręgosłupem} drzewa nazywamy ścieżkę od korzenia do węzła z najmniejszym/największym kluczem (złożoną wyłącznie z lewych/prawych krawędzi).
\end{definition}
Rozważmy teraz długość kręgosłupów dzieci dodawanego węzła w czasie operacji \texttt{insert}.
Nie trudno zauważyć, że początkowo oba są długości $0$ oraz, że każda rotacja w lewo wydłuża prawy kręgosłup lewego dziecka o $1$.
Analogicznie każda rotacja w prawo wydłuża lewy kręgosłup prawego drzewa o $1$.
Wynika stąd, że ilość rotacji potrzebnych przy wstawianiu węzła jest równa długości lewego kręgosłupa prawego dziecka i prawego kręgosłupa lewego dziecka nowo wstawionego węzła (po zakończeniu procedury).

Spróbujmy teraz określić wartości oczekiwane tych parametrów.
Weźmy dwa różna węzły $x$ i $y$ należące do drzewca, oznaczmy $i=y.key$ i $k=x.key$, i wyznaczmy zmienną losową:

$$
X_{ik} =
  \begin{cases} 
  1 &  y \in\ $prawego\ kręgosłupa\ lewego\ poddrzewa\ x$\\
  0 & $wpp.$
  \end{cases}
$$

Pokażemy teraz, że $X_{ik} = 1 \iff y.priority > x.priority \land y.key < x.key \land (\forall z\ y.key < z.key < x.key \implies y.priority < z.priority)$

Implikacja w prawo wynika wprost z definicji drzewca.
Rozważmy zatem implikację w drugą stronę.
Ponieważ $y.priority > x.priority \land y.key < x.key$ to $y$ należy do lewego poddrzewa $x$.
Teraz, gdyby $y$ nie należał do prawego kręgosłupa lewego poddrzewa $x$ to musiałby istnieć $z$ t.że $y.key < z.key < x.key$ i $y.priority > z.priority$, co daje sprzeczność.

Bez straty ogólności załóżmy teraz, że klucze są kolejnymi dodatnimi liczbami naturalnymi ($[1,n]$) i spróbujmy obliczyć $P(X_{ik})$.

Rozważmy teraz węzły o kluczach z $[i, k]$, jeśli chcemy, żeby $\forall z\in[i+1,k-1]\ x.priority < y.priority < z.priority$ to spośród wszystkich $(k-i+1)!$ permutacji interesują nas te, w których $y.priority$ i $x.priority$ są kolejno na dwóch pierwszych pozycjach, takich permutacji jest  $(k-i-1)!$.
Stąd $P(X_{ik}) = \frac{(k -i - 1)!}{(k -i + 1)!} =  \frac{1}{(k-i+1)(k-i)}$.

Teraz policzmy:
$$
\mathbf{E}[\sum_{i=1}^{k}X_{ik}]=
\sum_{i=1}^{k}\mathbf{E}[X_{ik}]=
\sum_{i=1}^{k}\frac{1}{(k-i+1)(k-i)}=
\sum_{i=1}^{k}\frac{1}{i(i+1)}=
\sum_{i=1}^{k}(\frac{1}{i}-\frac{1}{i+1})=
1-\frac{1}{k}
$$

Po przeprowadzeniu analogicznego rozumowania dla lewego kręgosłupa prawego poddrzewa (klucze z $[k,n]$) otrzymujemy wartość oczekiwaną $1 - \frac{1}{n-k+1}$.

Co razem daje nam oczekiwaną ilość rotacji równą $1 - \frac{1}{k} + 1 - \frac{1}{n-k+1} = 2 -  \frac{1}{k} - \frac{1}{n-k+1} < 2$.

Identyczna liczba rotacji dla \texttt{delete} wynika wprost z powyższego oraz Twierdzenia \ref{unique treap}.
\end{proof}

Powyższe twierdzenia pokazują, że wysokość drzewców, a tym samym operacje na nich, nie tylko mają dobrą złożoność asymptotyczną, ale też, że (oczekiwany) narzut związany z rotacjami jest ograniczony przez niewielką stałą.

\begin{algorithm}
  \DontPrintSemicolon
  \SetAlgorithmName{Algorytm}{}

  \KwData{ root }

  $new\_root \leftarrow root.right$\;
  $root.right \leftarrow new\_root.left$\;
  $new\_root.left \leftarrow root$\;
  \Return $new\_root$\;
  
  \caption{\texttt{rotateLeft (rotacja w prawo jest analogiczna)}}
  \label{treap-rotate-left}
\end{algorithm}

\begin{algorithm}
  \DontPrintSemicolon
  \SetAlgorithmName{Algorytm}{}

  \KwData{ root, value }
  \If{$root = null$}
  {
    \Return $Node(value, random())$\;
  }
  \ElseIf{$root.key = value$}
  {
    \Return $root$\;
  }
  \ElseIf{$root.key > value$}
  {
    $root.left \leftarrow insert(root.left, value)$\;
    \If{$root.left.priority < root.priority$}
    {
      $root \leftarrow rotateLeft(root)$\;
    }
  }
  \ElseIf{$root.key < value$}
  {
    $root.right \leftarrow insert(root.right, value)$\;
    \If{$root.right.priority < root.priority$}
    {
      $root \leftarrow rotateRight(root)$\;
    }
  }
  
  \Return root\;
  \caption{\texttt{insert}}
  \label{treap-insert}
\end{algorithm}

\begin{algorithm}
  \DontPrintSemicolon
  \SetAlgorithmName{Algorytm}{}

  \KwData{ root, value }
  
  \If{$root = null$}
    {
      \Return $null$\;
    }
  \ElseIf{$root.key > value$}
  {
     $root.left \leftarrow delete(root->left, value)$\;
  }
  \ElseIf{$root.key < value$}
  {
     $root.right \leftarrow delete(root->right, value)$\;
  }
  \ElseIf{$root.key = value$}
  {
  	\If{$root.left = null$}
  	{
  	  \Return $root.right$\;
  	}
  	\ElseIf{$root.right = null$}
  	{
  	  \Return $root.left$\;
  	}
  	\ElseIf{$root.left.priority < root.right.priority$}
  	{
  	  $root \leftarrow rotateLeft(root)$\;
  	  $root.left \leftarrow delete(root.left, value)$\;
  	}
  	\Else
  	{
  	  $root \leftarrow rotateRight(root)$\;
  	  $root.right \leftarrow delete(root.right, value)$\;
  	}
  }
  \Return $root$\;
  \caption{\texttt{delete}}
  \label{treap-delete}
\end{algorithm}
